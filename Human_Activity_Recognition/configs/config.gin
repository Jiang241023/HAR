# Architectures
lstm_like.lstm_units = 32
lstm_like.n_blocks = 4
lstm_like.dense_units = 128
lstm_like.dropout_rate_lstm_block = 0.3
lstm_like.dropout_rate_dense_layer = 0.3

#gru_like.gru_units = 64
#gru_like.n_blocks = 2
#gru_like.dense_units = 128
#gru_like.dropout_rate = 0.5

#transformer_like.n_blocks = 5
#transformer_like.dense_units = 128
#transformer_like.dropout_rate = 0.5

# Layers
#layers.lstm_block.lstm_units = 32
#layers.lstm_block.dropout_rate = 0.5

#layers.gru_block.gru_units = 64
#layers.gru_block.dropout_rate = 0.5

#layers.transformer_block.num_heads = 4
#layers.transformer_block.ff_dim = 128 * layers.transformer_block.num_heads
#layers.transformer_block.ff_dim = 512
#layers.transformer_block.dropout_rate = 0.5

# Training
Trainer.batch_size = 128
Trainer.total_epochs = 50
#Trainer.learning_rate = 1e-4

# Input pipeline
load.name = 'HAPT'
load.data_dir = r'E:\DL_LAB_HAPT_DATASET\HAPT_Data_Set\RawData'
load.labels_file = r'E:\DL_LAB_HAPT_DATASET\HAPT_Data_Set\RawData\labels.txt'
load.batch_size = 128
#prepare.caching = True

# Eval
eval.evaluate.num_classes = 12

# Metrics
metrics.ConfusionMatrix.num_classes = 12
metrics.ConfusionMatrix.name = "confusion_matrix"
metrics.ConfusionMatrix.labels_name = ['walking', 'walking_upstairs', 'walking_downstairs',
                                        'sitting', 'standing', 'laying', 'stand-sit',
                                       'sit-stand', 'sit-lie', 'lie-sit', 'stand-lie', 'lie-stand']
metrics.ConfusionMatrix.save_path = r'E:\DL_LAB_HAPT\confusion_matrix\cm.png'

